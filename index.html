<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kun-Yu Lin</title>

    <meta name="author" content="Kun-Yu Lin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kun-Yu Lin 
                </p>
                <p>
		I obtained my PhD degree from Sun Yat-set University, under the supervision of <a href="https://www.isee-ai.cn/~zhwshi/index.html">Wei-Shi Zheng</a>. 
		Prior to this, I obtained my Bachelor's degree and Master degree from Sun Yat-Sen University.
		During my PhD, I was fortunate to have the opportunity to study as a visiting student at MMLab@NTU, under the supervision of <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a> and <a href="https://henghuiding.github.io/">Henghui Ding</a>.  
                My research interests include computer vision and machine learning. 
                </p>
                <p style="text-align:center">
                  <a href="kunyulin14@outlook.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=tkUBeeQAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/kunyulin/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:90%;max-width:90%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/head.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
		
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		  <tr>
              	  <td style="padding:20px;width:100%;vertical-align:middle">
			  <h2>News</h2>
		  </td>
		  </tr>
		  <tr> <td>&nbsp; &nbsp; &nbsp; &nbsp; <b>&#10053 07/2024:</b> One paper was accepted to TPAMI.  
		  </td>
		  </tr>
		  <tr> <td>&nbsp; &nbsp; &nbsp; &nbsp; <b>&#10053 03/2024:</b> Releasing <a href="https://arxiv.org/abs/2403.01560">XOV-Action</a>, the first cross-domain open-vocabulary action recognition benchmark!
		  </td></tr>
		  <tr> <td>&nbsp; &nbsp; &nbsp; &nbsp; <b>&#10053 09/2023:</b> One paper was accepted to NeurIPS 2023.  
		  </td></tr>
		  <tr> <td>&nbsp; &nbsp; &nbsp; &nbsp; <b>&#10053 07/2023:</b> One paper was accepted to ICCV 2023.  
		  </td></tr>
		  <tr> <td>&nbsp; &nbsp; &nbsp; &nbsp; <b>&#10053 03/2023:</b> Two papers were accepted to CVPR 2023.  
		  </td></tr>
		<tr>  <td> &nbsp; </td></tr>
          </tbody></table>
		
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Works</h2>
                <p>
                Most of my research is about human video understanding, transferable and generalizable deep learning, and robot learning. 
		Some papers are <span class="highlight">highlighted</span>.
		# denotes equal contributions. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="xov_action()" onmouseover="xov_action()" bgcolor="#ffffd0">
<!--     <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()"> -->
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
<!--           <div class="two" id='xovaction'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/xovaction.png' width=100%>
        </div>
<!--         <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script> -->
      </td>
	    
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2403.01560">
	<span class="papertitle">Rethinking CLIP-based Video Learners in Cross-Domain Open-Vocabulary Action Recognition</span>
        </a>
        <br>
        <strong>Kun-Yu Lin</strong>, Henghui Ding, Jiaming Zhou, Yu-Ming Tang, Yi-Xing Peng, Zhilin Zhao, Chen Change Loy, Wei-Shi Zheng
<!--         <a href="https://bmild.github.io/">Ben Mildenhall</a> -->
        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2403.01560">arXiv</a>
        /
        <a href="https://github.com/KunyuLin/XOV-Action/">github</a>
        <p></p>
        <p>
	The first benchmark, named <a href="https://github.com/KunyuLin/XOV-Action/">XOV-Action</a>, for the cross-domain open-vocabulary action recognition task, 
	and a simple yet effective method to address the scene bias for the task. 
        </p>
      </td>
    </tr>

    <tr onmouseout="hctransformer()" onmouseover="hctransformer()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/hctransformer.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/">
	<span class="papertitle">Human-Centric Transformer for Domain Adaptive Action Recognition</span>
        </a>
        <br>
        <strong>Kun-Yu Lin</strong>, Jiaming Zhou, Wei-Shi Zheng
        <br>
        <em>TPAMI</em>, 2024
        <br>
        <a href="https://arxiv.org/">arXiv</a>
        <p></p>
        <p>
	A human-centric video network to address the context bias in domain adaptive action recognition.  
        </p>
      </td>
    </tr>

    <tr onmouseout="stdn()" onmouseover="stdn()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
<!--           <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/stdn.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2310.17942">
	<span class="papertitle">Diversifying Spatial-Temporal Perception for Video Domain Generalization</span>
        </a>
        <br>
        <strong>Kun-Yu Lin</strong>, Jia-Run Du, Yipeng Gao, Jiaming Zhou, Wei-Shi Zheng
        <br>
        <em>NeurIPS</em>, 2023
        <br>
        <a href="https://openreview.net/forum?id=YsZTDcIQwQ">paper</a>
        /
        <a href="https://arxiv.org/abs/2310.17942">arXiv</a>
        /
        <a href="https://github.com/KunyuLin/STDN/">github</a>
        <p></p>
        <p>
	A diversity-aware video network to address the bias to domain-specific information in video domain generalization. 
        </p>
      </td>
    </tr>

    <tr onmouseout="e3p()" onmouseover="e3p()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/e3p.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf">
	<span class="papertitle">Event-Guided Procedure Planning from Instructional Videos with Text Supervision</span>
        </a>
        <br>
        An-Lan Wang#, <strong>Kun-Yu Lin#</strong>, Jia-Run Du, Jingke Meng, Wei-Shi Zheng
        <br>
        <em>ECCV</em>, 2022
        <br>
        <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf">paper</a>
        /
        <a href="https://arxiv.org/abs/2308.08885">arXiv</a>
        <p></p>
        <p>
	A new event-guided paradigm for procedure planning in instructional videos. 
        </p>
      </td>
    </tr>

    <tr onmouseout="asyfod()" onmouseover="asyfod()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/asyfod.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_AsyFOD_An_Asymmetric_Adaptation_Paradigm_for_Few-Shot_Domain_Adaptive_Object_CVPR_2023_paper.pdf">
	<span class="papertitle">AsyFOD: An Asymmetric Adaptation Paradigm for Few-Shot Domain Adaptive Object Detection</span>
        </a>
        <br>
        Yipeng Gao#, <strong>Kun-Yu Lin#</strong>, Junkai Yan, Yaowei Wang, Wei-Shi Zheng
        <br>
        <em>ECCV</em>, 2022
        <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_AsyFOD_An_Asymmetric_Adaptation_Paradigm_for_Few-Shot_Domain_Adaptive_Object_CVPR_2023_paper.pdf">paper</a>
        /
        <a href="https://github.com/Hlings/AsyFOD">github</a>
        <p></p>
        <p>
	An asymmetric adaptation paradigm for few-shot domain adaptive object detection. 
        </p>
      </td>
    </tr>
		  
		  
    <tr onmouseout="cwan()" onmouseover="cwan()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/cwan.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930520.pdf">
	<span class="papertitle">Adversarial Partial Domain Adaptation by Cycle Inconsistency</span>
        </a>
        <br>
        <strong>Kun-Yu Lin</strong>, Jiaming Zhou, Yukun Qiu, Wei-Shi Zheng
        <br>
        <em>ECCV</em>, 2022
        <br>
        <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930520.pdf">paper</a>
        /
        <a href="https://github.com/KunyuLin/CWAN">github</a>
        <p></p>
        <p>
	A simple yet effective method based on cycle transformation to filter out outlier classes in partial domain adaptation. 
        </p>
      </td>
    </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Services</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
<!--               <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td> -->
              <td width="75%" valign="center">
		Reviewer of CVPR23, CVPR24
                <br>
		Reviewer of ICCV23
                <br>
		Reviewer of ECCV24
                <br>
		Reviewer of NeurIPS24
                <br>
		Reviewer of IJCAI24
                <br>
		Reviewer of TCSVT
                <br>
		Reviewer of Neurocomputing
                <br>
              </td>
            </tr>
          </tbody></table>
		
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
			This website borrows from Jon Barron.
<!--                   Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page. -->
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
